## üíª Kunj Pathak | Backend & Data Engineer

---

### **üìç Introduction & Core Expertise**

[cite_start]A dynamic **Software Engineer** specializing in the design and implementation of robust, secure backend systems[cite: 27, 45]. [cite_start]With professional experience in **Java/Spring Boot** [cite: 4, 5][cite_start], I focus on delivering scalable REST APIs, enforcing **TDD/SOLID Principles** for code quality [cite: 10, 42][cite_start], and managing development using **Agile/Scrum** practices[cite: 10, 27].

[cite_start]My expertise is strongly complemented by a background in **Data Engineering** (DBT, PySpark, ADF) [cite: 7, 15, 21] [cite_start]and **Cloud-Native infrastructure** (Kubernetes, Terraform on Azure/GCP)[cite: 8, 48, 50].

---

### **üõ†Ô∏è Technical Competencies**

Highlighting the most relevant skills first.

| Category | Key Technologies & Concepts |
| :--- | :--- |
| **Backend & Core** | [cite_start]**Java (Spring Boot, Spring Security)**, **.NET Core**, Microservices, REST APIs, JUnit, JWT, TDD, SOLID [cite: 4, 5, 10] |
| **Data Stack** | [cite_start]**DBT**, **PySpark**, Azure Data Factory (ADF), Databricks, Apache Spark, SQL (MySQL, OracleDB), NoSQL (MongoDB) [cite: 6, 7, 15, 21] |
| **DevOps & Cloud** | [cite_start]**Kubernetes** (GKE), **Terraform**, **Docker**, CI/CD (Cloud Build, Jenkins), Microsoft **Azure**, **GCP**, AWS [cite: 8, 48, 50] |
| **Frontend** | [cite_start]**ReactJS**, JavaScript, HTML, CSS (Tailwind CSS) [cite: 4, 5] |

---

### **üí° Professional Highlights & Impact**

Concrete examples of engineering work and impact from your resume.

* [cite_start]**Backend Engineering:** Implemented secure backend services using **Spring Boot**, architecting scalable front-end systems with **ReactJS**[cite: 27, 28]. [cite_start]Led the development of key APIs (registration, payments) with **92% code coverage** via TDD[cite: 41, 42].
* [cite_start]**Data Pipeline Optimization:** Developed and maintained **DBT models** to enhance data transformation and enforce governance[cite: 15]. [cite_start]Automated **Azure Data Factory (ADF) pipelines** to efficiently ingest and transform large datasets into Azure SQL[cite: 16].
* [cite_start]**Cloud Architecture:** Designed and deployed a **Microservices Architecture** on **GCP** using **Kubernetes** and **Docker**[cite: 48, 49]. [cite_start]Automated CI/CD pipelines and managed infrastructure provisioning via **Terraform** for consistent deployments[cite: 50].

---
